{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Step Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('next_h error: ', 1.8503734796991392e-09)\n"
     ]
    }
   ],
   "source": [
    "from code_base.rnn_layers import rnn_step_forward\n",
    "from code_base.layer_utils import rel_error\n",
    "import numpy as np\n",
    "\n",
    "N, D, H = 3, 10, 4\n",
    "x = np.linspace(-0.4, 0.7, num=N*D).reshape(N, D)\n",
    "prev_h = np.linspace(-0.2, 0.5, num=N*H).reshape(N, H)\n",
    "Wx = np.linspace(-0.1, 0.9, num=D*H).reshape(D, H)\n",
    "Wh = np.linspace(-0.3, 0.7, num=H*H).reshape(H, H)\n",
    "b = np.linspace(-0.2, 0.4, num=H)\n",
    "next_h, _ = rnn_step_forward(x, prev_h, Wx, Wh, b)\n",
    "expected_next_h = np.asarray([\n",
    "[-0.58172089, -0.50182032, -0.41232771, -0.31410098],\n",
    "[ 0.66854692, 0.79562378, 0.87755553, 0.92795967],\n",
    "[ 0.97934501, 0.99144213, 0.99646691, 0.99854353]])\n",
    "print('next_h error: ', rel_error(expected_next_h, next_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import rnn_step_forward\n",
    "import numpy as np\n",
    "\n",
    "x_shape = (3, 874)\n",
    "Wx_shape = (874, 128)\n",
    "h_shape = (3, 128)\n",
    "Wh_shape = (128, 128)\n",
    "b_shape = (128,)\n",
    "x = np.loadtxt('./input_files/x.csv', delimiter=',')\n",
    "x = x.reshape(x_shape)\n",
    "Wx = np.loadtxt('./input_files/Wx.csv', delimiter=',')\n",
    "Wx = Wx.reshape(Wx_shape)\n",
    "prev_h = np.loadtxt('./input_files/prev_h.csv', delimiter=',')\n",
    "prev_h = prev_h.reshape(h_shape)\n",
    "Wh = np.loadtxt('./input_files/Wh.csv', delimiter=',')\n",
    "Wh = Wh.reshape(Wh_shape)\n",
    "b = np.loadtxt('./input_files/b.csv', delimiter=',')\n",
    "out, _ = rnn_step_forward(x, prev_h, Wx, Wh, b)\n",
    "np.savetxt('./output_files/rnn_step_forward_out.csv', out.ravel(), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Step Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dx error: ', 3.6350338657810377e-11)\n",
      "('dprev_h error: ', 4.2909084975836541e-11)\n",
      "('dWx error: ', 3.4665488670218427e-11)\n",
      "('dWh error: ', 5.7671648302572833e-11)\n",
      "('db error: ', 1.3124598390789563e-10)\n"
     ]
    }
   ],
   "source": [
    "from code_base.rnn_layers import rnn_step_forward, rnn_step_backward\n",
    "from code_base.gradient_check import *\n",
    "from code_base.layer_utils import rel_error\n",
    "import numpy as np\n",
    "\n",
    "N, D, H = 4, 5, 6\n",
    "x = np.random.randn(N, D)\n",
    "h = np.random.randn(N, H)\n",
    "Wx = np.random.randn(D, H)\n",
    "Wh = np.random.randn(H, H)\n",
    "b = np.random.randn(H)\n",
    "out, cache = rnn_step_forward(x, h, Wx, Wh, b)\n",
    "dnext_h = np.random.randn(*out.shape)\n",
    "fx = lambda x: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "fh = lambda prev_h: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "fWx = lambda Wx: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "fWh = lambda Wh: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "fb = lambda b: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dnext_h)\n",
    "dprev_h_num = eval_numerical_gradient_array(fh, h, dnext_h)\n",
    "dWx_num = eval_numerical_gradient_array(fWx, Wx, dnext_h)\n",
    "dWh_num = eval_numerical_gradient_array(fWh, Wh, dnext_h)\n",
    "db_num = eval_numerical_gradient_array(fb, b, dnext_h)\n",
    "dx, dprev_h, dWx, dWh, db = rnn_step_backward(dnext_h, cache)\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dprev_h error: ', rel_error(dprev_h_num, dprev_h))\n",
    "print('dWx error: ', rel_error(dWx_num, dWx))\n",
    "print('dWh error: ', rel_error(dWh_num, dWh))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import rnn_step_forward, rnn_step_backward\n",
    "import numpy as np\n",
    "\n",
    "x_shape = (3, 874)\n",
    "Wx_shape = (874, 128)\n",
    "h_shape = (3, 128)\n",
    "Wh_shape = (128, 128)\n",
    "b_shape = (128,)\n",
    "x = np.loadtxt('./input_files/x.csv', delimiter=',')\n",
    "x = x.reshape(x_shape)\n",
    "Wx = np.loadtxt('./input_files/Wx.csv', delimiter=',')\n",
    "Wx = Wx.reshape(Wx_shape)\n",
    "prev_h = np.loadtxt('./input_files/prev_h.csv', delimiter=',')\n",
    "prev_h = prev_h.reshape(h_shape)\n",
    "Wh = np.loadtxt('./input_files/Wh.csv', delimiter=',')\n",
    "Wh = Wh.reshape(Wh_shape)\n",
    "b = np.loadtxt('./input_files/b.csv', delimiter=',')\n",
    "out, cache = rnn_step_forward(x, prev_h, Wx, Wh, b)\n",
    "dhout = np.loadtxt('./input_files/dho.csv', delimiter=',')\n",
    "dx, dh, dWx, dWh, db = rnn_step_backward(dhout, cache)\n",
    "np.savetxt('./output_files/rnn_step_backward_out_dx.csv', dx.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/rnn_step_backward_out_dh.csv', dh.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/rnn_step_backward_out_dwx.csv', dWx.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/rnn_step_backward_out_dwh.csv', dWh.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/rnn_step_backward_out_db.csv', db.ravel(), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('h error: ', 1.0452294936691702e-08)\n"
     ]
    }
   ],
   "source": [
    "from code_base.rnn_layers import rnn_forward\n",
    "from code_base.layer_utils import *\n",
    "import numpy as np\n",
    "\n",
    "N, T, D, H = 2, 3, 4, 5\n",
    "x = np.linspace(-0.1, 0.3, num=N*T*D).reshape(N, T, D)\n",
    "h0 = np.linspace(-0.3, 0.1, num=N*H).reshape(N, H)\n",
    "Wx = np.linspace(-0.2, 0.4, num=D*H).reshape(D, H)\n",
    "Wh = np.linspace(-0.4, 0.1, num=H*H).reshape(H, H)\n",
    "b = np.linspace(-0.7, 0.1, num=H)\n",
    "h, _ = rnn_forward(x, h0, Wx, Wh, b)\n",
    "expected_h = np.asarray([\n",
    "[[-0.42070749, -0.27279261, -0.11074945, 0.05740409, 0.22236251],\n",
    "[-0.39525808, -0.22554661, -0.0409454, 0.14649412, 0.32397316],\n",
    "[-0.42305111, -0.24223728, -0.04287027, 0.15997045, 0.35014525],],\n",
    "[[-0.55857474, -0.39065825, -0.19198182, 0.02378408, 0.23735671],\n",
    "[-0.27150199, -0.07088804, 0.13562939, 0.33099728, 0.50158768],\n",
    "[-0.51014825, -0.30524429, -0.06755202, 0.17806392, 0.40333043]]])\n",
    "print('h error: ', rel_error(expected_h, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import rnn_forward\n",
    "import numpy as np\n",
    "\n",
    "x_all_shape = (3, 5, 874)\n",
    "Wx_shape = (874, 128)\n",
    "h_shape = (3, 128)\n",
    "Wh_shape = (128, 128)\n",
    "b_shape = (128,)\n",
    "x_all = np.loadtxt('./input_files/x_all.csv', delimiter=',')\n",
    "x_all = x_all.reshape(x_all_shape)\n",
    "Wx = np.loadtxt('./input_files/Wx.csv', delimiter=',')\n",
    "Wx = Wx.reshape(Wx_shape)\n",
    "h0 = np.loadtxt('./input_files/prev_h.csv', delimiter=',')\n",
    "h0 = prev_h.reshape(h_shape)\n",
    "Wh = np.loadtxt('./input_files/Wh.csv', delimiter=',')\n",
    "Wh = Wh.reshape(Wh_shape)\n",
    "b = np.loadtxt('./input_files/b.csv', delimiter=',')\n",
    "out, _ = rnn_forward(x_all, h0, Wx, Wh, b)\n",
    "np.savetxt('./output_files/rnn_forward_out.csv', out.ravel(), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dx error: ', 1.2908390932183091e-10)\n",
      "('dh0 error: ', 1.9630233992977988e-10)\n",
      "('dWx error: ', 1.9753491096596649e-10)\n",
      "('dWh error: ', 1.6641222126293984e-10)\n",
      "('db error: ', 8.4863874891102008e-11)\n"
     ]
    }
   ],
   "source": [
    "from code_base.rnn_layers import rnn_forward, rnn_backward\n",
    "from code_base.gradient_check import *\n",
    "from code_base.layer_utils import *\n",
    "import numpy as np\n",
    "\n",
    "N, D, T, H = 2, 3, 10, 5\n",
    "x = np.random.randn(N, T, D)\n",
    "h0 = np.random.randn(N, H)\n",
    "Wx = np.random.randn(D, H)\n",
    "Wh = np.random.randn(H, H)\n",
    "b = np.random.randn(H)\n",
    "out, cache = rnn_forward(x, h0, Wx, Wh, b)\n",
    "dout = np.random.randn(*out.shape)\n",
    "dx, dh0, dWx, dWh, db = rnn_backward(dout, cache)\n",
    "fx = lambda x: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fh0 = lambda h0: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fWx = lambda Wx: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fWh = lambda Wh: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fb = lambda b: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "dh0_num = eval_numerical_gradient_array(fh0, h0, dout)\n",
    "dWx_num = eval_numerical_gradient_array(fWx, Wx, dout)\n",
    "dWh_num = eval_numerical_gradient_array(fWh, Wh, dout)\n",
    "db_num = eval_numerical_gradient_array(fb, b, dout)\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dh0 error: ', rel_error(dh0_num, dh0))\n",
    "print('dWx error: ', rel_error(dWx_num, dWx))\n",
    "print('dWh error: ', rel_error(dWh_num, dWh))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import rnn_forward, rnn_backward\n",
    "import numpy as np\n",
    "\n",
    "x_all_shape = (3, 5, 874)\n",
    "Wx_shape = (874, 128)\n",
    "h_shape = (3, 128)\n",
    "Wh_shape = (128, 128)\n",
    "b_shape = (128,)\n",
    "dh_all_shape = (3, 5, 128)\n",
    "x_all = np.loadtxt('./input_files/x_all.csv', delimiter=',')\n",
    "x_all = x_all.reshape(x_all_shape)\n",
    "Wx = np.loadtxt('./input_files/Wx.csv', delimiter=',')\n",
    "Wx = Wx.reshape(Wx_shape)\n",
    "h0 = np.loadtxt('./input_files/prev_h.csv', delimiter=',')\n",
    "h0 = h0.reshape(h_shape)\n",
    "Wh = np.loadtxt('./input_files/Wh.csv', delimiter=',')\n",
    "Wh = Wh.reshape(Wh_shape)\n",
    "b = np.loadtxt('./input_files/b.csv', delimiter=',')\n",
    "out, cache = rnn_forward(x_all, h0, Wx, Wh, b)\n",
    "dhout = np.loadtxt('./input_files/dho_all.csv', delimiter=',')\n",
    "dhout = dhout.reshape(dh_all_shape)\n",
    "dx_all, dh0, dWx, dWh, db = rnn_backward(dhout, cache)\n",
    "np.savetxt('./output_files/rnn_backward_out_dx.csv', dx_all.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/rnn_backward_out_dh0.csv', dh0.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/rnn_backward_out_dwx.csv', dWx.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/rnn_backward_out_dwh.csv', dWh.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/rnn_backward_out_db.csv', db.ravel(), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Temporal Bi-directional Concatenation Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import bidirectional_rnn_concatenate_forward\n",
    "from code_base.layer_utils import *\n",
    "import numpy as np\n",
    "\n",
    "N, T, H = 2, 4, 3\n",
    "h = np.linspace(-0.5, 0, num=N*T*H).reshape(N, T, H)\n",
    "hr = np.linspace(0, 0.5, num=N*T*H).reshape(N, T, H)\n",
    "mask = np.ones((N,T))\n",
    "mask[0][3] = 0 # length of s1 is 3\n",
    "mask[1][2] = mask[1][3] = 0 # length of s2 is 2\n",
    "ho, _ = bidirectional_rnn_concatenate_forward(h, hr, mask)\n",
    "expected_ho = np.array([[\n",
    "[-0.5, -0.47826087, -0.45652174, 0.13043478, 0.15217391, 0.17391304],\n",
    "[-0.43478261, -0.41304348, -0.39130435, 0.06521739, 0.08695652, 0.10869565],\n",
    "[-0.36956522, -0.34782609, -0.32608696, 0., 0.02173913, 0.04347826],\n",
    "[0., 0., 0., 0., 0., 0.]],\n",
    "[[-0.23913043, -0.2173913 , -0.19565217, 0.32608696, 0.34782609, 0.36956522],\n",
    "[-0.17391304, -0.15217391, -0.13043478, 0.26086957, 0.2826087, 0.30434783],\n",
    "[0., 0., 0., 0., 0., 0.],\n",
    "[0., 0., 0., 0., 0., 0.]]])\n",
    "print('ho error: ', rel_error(expected_ho, ho, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import bidirectional_rnn_concatenate_forward\n",
    "from code_base.gradient_check import *\n",
    "import numpy as np\n",
    "\n",
    "h_shape = (3, 5, 128)\n",
    "mask_shape = (3, 5)\n",
    "h = np.loadtxt('./input_files/h_all.csv', delimiter=',')\n",
    "h = h.reshape(h_shape)\n",
    "hr = np.loadtxt('./input_files/h_all_r.csv', delimiter=',')\n",
    "hr = hr.reshape(h_shape)\n",
    "mask = np.loadtxt('./input_files/mask.csv', delimiter=',')\n",
    "mask = mask.reshape(mask_shape)\n",
    "hout, _ = bidirectional_rnn_concatenate_forward(h, hr, mask)\n",
    "np.savetxt('./output_files/bidirectional_rnn_concatenate_forward_out.csv', hout.ravel(), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Temporal Bi-directional Concatenation Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import bidirectional_rnn_concatenate_forward, bidirectional_rnn_concatenate_backward\n",
    "from code_base.layer_utils import *\n",
    "from code_base.gradient_check import *\n",
    "import numpy as np\n",
    "\n",
    "N, T, H = 2, 4, 3\n",
    "h = np.linspace(-0.5, 0, num=N*T*H).reshape(N, T, H)\n",
    "hr = np.linspace(0, 0.5, num=N*T*H).reshape(N, T, H)\n",
    "mask = np.ones((N,T))\n",
    "mask[0][3] = 0 # length of s1 is 3\n",
    "mask[1][2] = mask[1][3] = 0 # length of s2 is 2\n",
    "ho, cache = bidirectional_rnn_concatenate_forward(h, hr, mask)\n",
    "dho = np.linspace(0., 0.5, num=N*T*2*H).reshape(N, T, 2*H)\n",
    "dh, dhr = bidirectional_rnn_concatenate_backward(dho, cache)\n",
    "fh = lambda h: bidirectional_rnn_concatenate_forward(h, hr, mask)[0]\n",
    "fhr = lambda hr: bidirectional_rnn_concatenate_forward(h, hr, mask)[0]\n",
    "dh_num = eval_numerical_gradient_array(fh, h, dho)\n",
    "dhr_num = eval_numerical_gradient_array(fhr, hr, dho)\n",
    "print('dh error: ', rel_error(dh_num, dh, mask))\n",
    "print('dhr error: ', rel_error(dhr_num, dhr, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import bidirectional_rnn_concatenate_forward, bidirectional_rnn_concatenate_backward\n",
    "import numpy as np\n",
    "\n",
    "h_shape = (3, 5, 128)\n",
    "mask_shape = (3, 5)\n",
    "h = np.loadtxt('./input_files/h_all.csv', delimiter=',')\n",
    "h = h.reshape(h_shape)\n",
    "hr = np.loadtxt('./input_files/h_all_r.csv', delimiter=',')\n",
    "hr = hr.reshape(h_shape)\n",
    "mask = np.loadtxt('./input_files/mask.csv', delimiter=',')\n",
    "mask = mask.reshape(mask_shape)\n",
    "hout, cache = bidirectional_rnn_concatenate_forward(h, hr, mask)\n",
    "dhout = np.loadtxt('./input_files/dhc_all.csv', delimiter=',')\n",
    "dhout = dhout.reshape(3, 5, 256)\n",
    "dh, dhr = bidirectional_rnn_concatenate_backward(dhout, cache)\n",
    "np.savetxt('./output_files/bidirectional_rnn_concatenate_backward_out_h.csv', dh.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/bidirectional_rnn_concatenate_backward_out_hr.csv', dhr.ravel(), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN for Sentiment Analysis - Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loss: ', 2.9961922682286128)\n",
      "('expected loss: ', 2.99619226823)\n",
      "('difference: ', 1.3873346915715956e-12)\n"
     ]
    }
   ],
   "source": [
    "from code_base.classifiers.rnn import *\n",
    "# If you do brnn, please import from code_base.classifiers.brnn instead\n",
    "import numpy as np\n",
    "\n",
    "N, H, A, O = 2, 6, 5, 2\n",
    "word_to_idx = { 'awesome': 0, 'reading':1, 'pretty': 2, 'dog': 3, 'movie': 4,\n",
    "                'liked': 5, 'most': 6, 'admired': 7, 'bad': 8, 'fucking': 9}\n",
    "V = len(word_to_idx)\n",
    "T = 4\n",
    "model = SentimentAnalysisRNN(word_to_idx,\n",
    "    hidden_dim=H,\n",
    "    fc_dim=A,\n",
    "    output_dim=O,\n",
    "    cell_type='rnn',\n",
    "    dtype=np.float64)\n",
    "# Set all model parameters to fixed values\n",
    "for k, v in model.params.items():\n",
    "    model.params[k] = np.linspace(-1.4, 1.3, num=v.size).reshape(*v.shape)\n",
    "labels = np.array([1, 0], dtype=np.int32)\n",
    "wordvecs = np.zeros((N, T, V))\n",
    "wordvecs[0, 0, 0] = wordvecs[0, 1, 5] = wordvecs[0, 2, 2] = wordvecs[0, 3, 7] = 1\n",
    "wordvecs[1, 0, 4] = wordvecs[1, 1, 8] = wordvecs[1, 2, 5] = 1\n",
    "mask = np.ones((N, T))\n",
    "mask[1, 3] = 0\n",
    "loss, grads = model.loss(wordvecs, labels, mask)\n",
    "expected_loss = 2.99619226823\n",
    "# For brnn, the expected_loss should be 2.9577205234\n",
    "print('loss: ', loss)\n",
    "print('expected loss: ', expected_loss)\n",
    "print('difference: ', abs(loss - expected_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN for Sentiment Analysis - Backward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_a relative error: 2.470576e-09\n",
      "W_fc relative error: 2.570463e-10\n",
      "Wh relative error: 1.117105e-07\n",
      "Wx relative error: 3.993306e-08\n",
      "b relative error: 9.065656e-09\n",
      "b_a relative error: 1.536972e-09\n",
      "b_fc relative error: 4.681212e-12\n"
     ]
    }
   ],
   "source": [
    "from code_base.classifiers.rnn import *\n",
    "# If you do brnn, please import from code_base.classifiers.brnn instead\n",
    "from code_base.gradient_check import *\n",
    "from code_base.layer_utils import rel_error\n",
    "import numpy as np\n",
    "\n",
    "N, T, H, A, O = 2, 4, 6, 5, 2\n",
    "word_to_idx = {'awesome': 0, 'reading':1, 'pretty': 2, 'dog': 3, 'movie': 4,\n",
    "                'liked': 5, 'most': 6, 'admired': 7, 'bad': 8, 'fucking': 9}\n",
    "V = len(word_to_idx)\n",
    "labels = np.array([1, 0], dtype=np.int32)\n",
    "wordvecs = np.zeros((N, T, V))\n",
    "wordvecs[0, 0, 0] = wordvecs[0, 1, 5] = wordvecs[0, 2, 2] = wordvecs[0, 3, 7] = 1\n",
    "wordvecs[1, 0, 4] = wordvecs[1, 1, 8] = wordvecs[1, 2, 5] = 1\n",
    "mask = np.ones((N, T))\n",
    "mask[1, 3] = 0\n",
    "model = SentimentAnalysisRNN(word_to_idx,\n",
    "    hidden_dim=H,\n",
    "    fc_dim=A,\n",
    "    output_dim=O,\n",
    "    cell_type='rnn',\n",
    "    dtype=np.float64,\n",
    ")\n",
    "loss, grads = model.loss(wordvecs, labels, mask)\n",
    "for param_name in sorted(grads):\n",
    "    f = lambda _: model.loss(wordvecs, labels, mask)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, model.params[param_name],\n",
    "verbose=False, h=1e-6)\n",
    "    e = rel_error(param_grad_num, grads[param_name])\n",
    "    print('%s relative error: %e' % (param_name, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/Inference on Small Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/shumin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "(Iteration 1 / 100) loss: 0.315483\n",
      "(Iteration 11 / 100) loss: 0.277323\n",
      "(Iteration 21 / 100) loss: 0.243838\n",
      "(Iteration 31 / 100) loss: 0.212798\n",
      "(Iteration 41 / 100) loss: 0.183810\n",
      "(Iteration 51 / 100) loss: 0.157254\n",
      "(Iteration 61 / 100) loss: 0.133639\n",
      "(Iteration 71 / 100) loss: 0.113249\n",
      "(Iteration 81 / 100) loss: 0.096055\n",
      "(Iteration 91 / 100) loss: 0.081789\n",
      "pres shape\n",
      "(100, 2)\n",
      "[0.31548343967565534, 0.31132750494621148, 0.30726501242820192, 0.30328813316793107, 0.29938976178801063, 0.29556341314794482, 0.29180320622693845, 0.28810375054463888, 0.28446016419503634, 0.28086803177403719, 0.27732331466184074, 0.27382237587789204, 0.27036192127612396, 0.26693897960286866, 0.26355087617813799, 0.26019523936042055, 0.25686995291485193, 0.2535731148759181, 0.25030307031438631, 0.24705840190193132, 0.24383783216702265, 0.24064028821111111, 0.23746489484411235, 0.23431090699804535, 0.23117772268995934, 0.22806487869667241, 0.22497203652790673, 0.22189899586238224, 0.21884563980212043, 0.21581197202287108, 0.21279806194449769, 0.20980405963192036, 0.20683018717938637, 0.20387675486212678, 0.20094408593483948, 0.19803259974846754, 0.19514273555641096, 0.19227499234343168, 0.18942985616872879, 0.18660786108327801, 0.18380955880546901, 0.18103551497113371, 0.17828630573829651, 0.1755625083399002, 0.17286468077171968, 0.17019339572953826, 0.16754921708796344, 0.16493267724184071, 0.16234430879771383, 0.15978463096272638, 0.15725410024089925, 0.15475320421390115, 0.15228235239172969, 0.14984196064828617, 0.14743239823855447, 0.14505400286687822, 0.14270709776408907, 0.14039194049981435, 0.13810878832329188, 0.13585783326589415, 0.13363926384948807, 0.13145322007922189, 0.12929979360135213, 0.12717907279623886, 0.12509108337690658, 0.12303584893388241, 0.12101333314202944, 0.11902348418321475, 0.11706621909504507, 0.11514142880584491, 0.1132489755282861, 0.11138868294614826, 0.10956037694452107, 0.10776383329985538, 0.1059988184025476, 0.10426507783390707, 0.10256233823443868, 0.10089030565874245, 0.099248670952460302, 0.097637097697257785, 0.096055257482240267, 0.094502785719572768, 0.092979328674333672, 0.091484499061809499, 0.090017921749544524, 0.088579191253912976, 0.087167906034930992, 0.085783666767421177, 0.08442604931266981, 0.083094645284237406, 0.081789020946517521, 0.08050876145785503, 0.079253437161178483, 0.078022628581120315, 0.076815894454830516, 0.07563281511213131, 0.07447295925531848, 0.073335898986768316, 0.072221215037620273, 0.071128474083464635]\n"
     ]
    }
   ],
   "source": [
    "from code_base.sentiment_analysis_solver import *\n",
    "from code_base.classifiers.rnn import *\n",
    "# If you do brnn, please import from code_base.classifiers.brnn instead\n",
    "from code_base.data_utils import *\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "download_corpus()\n",
    "small_data = load_data('code_base/datasets/train.csv', sample=True)\n",
    "small_rnn_model = SentimentAnalysisRNN(\n",
    "    cell_type='rnn',\n",
    "    word_to_idx=load_dictionary('code_base/datasets/dictionary.csv')\n",
    ")\n",
    "small_rnn_solver = SentimentAnalysisSolver(small_rnn_model,\n",
    "    small_data,\n",
    "    update_rule='sgd',\n",
    "    num_epochs=100,\n",
    "    batch_size=100,\n",
    "    optim_config={\n",
    "        'learning_rate': 5e-3,\n",
    "    },\n",
    "    lr_decay=1.0,\n",
    "    verbose=True,\n",
    "    print_every=10,\n",
    ")\n",
    "small_rnn_solver.train()\n",
    "\n",
    "# we will use the same batch of training data for inference\n",
    "# this is just to let you know the procedure of inference\n",
    "preds = small_rnn_solver.test(split='train')\n",
    "np.savetxt('./output_files/rnn_prediction_prob.csv', preds.ravel(), delimiter=',')\n",
    "# If you do brnn, please save result to ./output_files/brnn_prediction_prob.csv\n",
    "\n",
    "print(small_rnn_solver.loss_history)\n",
    "# Plot the training losses\n",
    "#plt.plot(small_rnn_solver.loss_history)\n",
    "#plt.xlabel('Iteration')\n",
    "#plt.ylabel('Loss')\n",
    "#plt.title('Training loss history')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
